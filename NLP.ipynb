{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ehzb3_QgIyeV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "For web scraping the websites and storing the text in text file\n",
        "\"\"\"\n",
        "\n",
        "URL=data[\"URL\"]\n",
        "ID=data[\"URL_ID\"]\n",
        "\n",
        "for u,i in zip(URL,ID):\n",
        "    # Send a GET request to the website\n",
        "    url = u\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Create a BeautifulSoup object to parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Find elements on the page using HTML tags and class names\n",
        "    title_element = soup.find(\"h1\")\n",
        "    title = title_element.text if title_element else \"\"\n",
        "    paragraphs = soup.find_all(\"p\")\n",
        "\n",
        "    # Extract the text of each paragraph and store it in a list\n",
        "    paragraph_texts = [paragraph.text for paragraph in paragraphs]\n",
        "\n",
        "    # Print the extracted data in a linear format\n",
        "    print(\"Title:\", title)\n",
        "    print(\"Paragraphs:\")\n",
        "    print(\"\\n\".join(paragraph_texts))\n",
        "\n",
        "    with open('C:/Users/Gnanabharathi/Downloads/Internship work May 19/'+str(i)+\".txt\", 'w', encoding='utf-8') as file:\n",
        "        file.write(title)\n",
        "        file.write(\"\\n\".join(paragraph_texts))"
      ],
      "metadata": {
        "id": "K7a5ZFbfIvgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZL6LHRxW7ksx"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "For doing Text Analysis on each website content by\n",
        "POSITIVE SCORE\n",
        "NEGATIVE SCORE\n",
        "POLARITY SCORE\n",
        "SUBJECTIVITY SCORE\n",
        "AVG SENTENCE LENGTH\n",
        "PERCENTAGE OF COMPLEX WORDS\n",
        "FOG INDEX\n",
        "AVG NUMBER OF WORDS PER SENTENCE\n",
        "COMPLEX WORD COUNT\n",
        "WORD COUNT\n",
        "SYLLABLE PER WORD\n",
        "PERSONAL PRONOUNS\n",
        "AVG WORD LENGTH\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open('C:/Users/Gnanabharathi/Downloads/20211030 Test Assignment-20230519T050226Z-001/20211030 Test Assignment/MasterDictionary/positive-words.txt', 'r') as file:\n",
        "    # Read the entire contents of the file\n",
        "    ps = file.read() #Positive words\n",
        "\n",
        "with open('C:/Users/Gnanabharathi/Downloads/20211030 Test Assignment-20230519T050226Z-001/20211030 Test Assignment/MasterDictionary/negative-words.txt', 'r') as file:\n",
        "    # Read the entire contents of the file\n",
        "    ns = file.read()  #Negative words\n",
        "\n",
        "ind=0\n",
        "URL=out[\"URL\"]\n",
        "ID=out[\"URL_ID\"]\n",
        "\n",
        "for u,i in zip(URL,ID):\n",
        "    # Send a GET request to the website\n",
        "    url = u\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Create a BeautifulSoup object to parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Find elements on the page using HTML tags and class names\n",
        "    title_element = soup.find(\"h1\")\n",
        "    title = title_element.text if title_element else \"\"\n",
        "    paragraphs = soup.find_all(\"p\")\n",
        "\n",
        "    # Extract the text of each paragraph and store it in a list\n",
        "    paragraph_texts = [paragraph.text for paragraph in paragraphs]\n",
        "\n",
        "    pos=0\n",
        "    neg=0\n",
        "    for i in title.split(\" \"):\n",
        "        if i in ps:\n",
        "            pos+=1\n",
        "    for i in paragraph_texts:\n",
        "        for j in i.split(\" \"):\n",
        "            if(j in ps):\n",
        "                pos+=1\n",
        "    out.loc[ind,\"POSITIVE SCORE\"]=pos\n",
        "\n",
        "    for i in title.split(\" \"):\n",
        "        if i in ns:\n",
        "            neg+=1\n",
        "    for i in paragraph_texts:\n",
        "        for j in i.split(\" \"):\n",
        "            if(j in ns):\n",
        "                neg+=1\n",
        "    out.loc[ind,\"NEGATIVE SCORE\"]=neg\n",
        "\n",
        "    pol=(pos-neg)/(pos+neg)\n",
        "    out.loc[ind,\"POLARITY SCORE\"]=pol\n",
        "\n",
        "    words=[]\n",
        "    for i in title.split(\" \"):\n",
        "        words.append(i)\n",
        "    for i in paragraph_texts:\n",
        "        for j in i.split(\" \"):\n",
        "            words.append(j)\n",
        "    sub=(pos+neg)/len((words))\n",
        "    out.loc[ind,\"SUBJECTIVITY SCORE\"]=sub\n",
        "\n",
        "    sen=[]\n",
        "    for i in title.split(\".\"):\n",
        "        sen.append(i)\n",
        "    for i in paragraph_texts:\n",
        "        for j in i.split(\".\"):\n",
        "            sen.append(j)\n",
        "\n",
        "    a=len(words)/len(sen)\n",
        "    out.loc[ind,\"AVG SENTENCE LENGTH\"]=len(words)/len(sen)\n",
        "\n",
        "    comp=[]\n",
        "    for i in title.split(\" \"):\n",
        "        if len(i) > 6 and syllables.estimate(i) >= 2:\n",
        "                comp.append(i)\n",
        "    for i in paragraph_texts:\n",
        "        for j in i.split(\" \"):\n",
        "            if len(j) > 6 and syllables.estimate(j) >= 2:\n",
        "                comp.append(j)\n",
        "    b=len(comp)/len(words)\n",
        "    out.loc[ind,\"PERCENTAGE OF COMPLEX WORDS\"]=len(comp)/len(words)\n",
        "\n",
        "    out.loc[ind,\"FOG INDEX\"]=(a+b)*0.4\n",
        "\n",
        "    out.loc[ind,\"AVG NUMBER OF WORDS PER SENTENCE\"]=a\n",
        "\n",
        "    cp=0\n",
        "    for i in title.split(\" \"):\n",
        "        if syllables.estimate(i) >= 2:\n",
        "                cp+=1\n",
        "    for i in paragraph_texts:\n",
        "        for j in i.split(\" \"):\n",
        "            if syllables.estimate(j) >= 2:\n",
        "                cp+=1\n",
        "    out.loc[ind,\"COMPLEX WORD COUNT\"]=cp\n",
        "\n",
        "    out.loc[ind,\"WORD COUNT\"]=len(words)\n",
        "\n",
        "    cp=0\n",
        "    for i in title.split(\" \"):\n",
        "        if syllables.estimate(i) >= 2:\n",
        "            for v in j:\n",
        "                if v=='a' or v=='e' or v=='i' or v=='o' or v=='u' or v=='A' or v=='E' or v=='I' or v=='O' or v=='U':\n",
        "                    cp+=1\n",
        "    for i in paragraph_texts:\n",
        "        for j in i.split(\" \"):\n",
        "            if syllables.estimate(j) >= 2:\n",
        "                for v in j:\n",
        "                    if v=='a' or v=='e' or v=='i' or v=='o' or v=='u' or v=='A' or v=='E' or v=='I' or v=='O' or v=='U':\n",
        "                        cp+=1\n",
        "    out.loc[ind,\"SYLLABLE PER WORD\"]=cp\n",
        "\n",
        "    pro=0\n",
        "    personal_pronouns = ['I', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'you', 'him', 'her', 'us', 'them']\n",
        "    for i in title.split(\" \"):\n",
        "        if i in personal_pronouns or i.lower() in personal_pronouns:\n",
        "                pro+=1\n",
        "    for i in paragraph_texts:\n",
        "        for j in i.split(\" \"):\n",
        "            if j in personal_pronouns or j.lower() in personal_pronouns:\n",
        "                pro+=1\n",
        "    out.loc[ind,\"PERSONAL PRONOUNS\"]=pro\n",
        "\n",
        "\n",
        "    ch=0\n",
        "    for i in title.split(\" \"):\n",
        "        for j in i:\n",
        "            ch+=1\n",
        "    for i in paragraph_texts:\n",
        "        for j in i.split(\" \"):\n",
        "            for k in j:\n",
        "                ch+=1\n",
        "    out.loc[ind,\"AVG WORD LENGTH\"]=ch/len(words)\n",
        "\n",
        "    ind+=1\n",
        "out.head()\n"
      ]
    }
  ]
}